# -*- coding: utf-8 -*-
"""HealthInsuranceChargesPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10TiQuCu48fYD0sX3ho2l2lm_SELzHjjA

#Insurance Amount prediction
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
# %matplotlib inline

df_train=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Projects/Health Insurance Charges Prediction/insurance.csv')

df_train.shape

df_train.columns

df_train.dtypes

"""Target variable 'Charges'"""

df_train['charges'].describe()

df_train['charges'].isnull().sum()

sns.displot(df_train['charges'],);

df_train.isnull().sum()

df_train.select_dtypes(include=np.number).columns.tolist()

df_train.columns[df_train.isnull().any()]

print (round((df_train.isnull().sum()).sort_values(ascending=False)))

print (round((df_train.isnull().sum() * 100/ len(df_train)),2).sort_values(ascending=False))

def missing_zero_values_table(df):
        zero_val = (df == 0.00).astype(int).sum(axis=0)
        mis_val = df.isnull().sum()
        mis_val_percent = 100 * df.isnull().sum() / len(df)
        mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)
        mz_table = mz_table.rename(
        columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})
        mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']
        mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)
        mz_table['Data Type'] = df.dtypes
        mz_table = mz_table[
            mz_table.iloc[:,1] != 0].sort_values(
        '% of Total Values', ascending=False).round(1)
        print ("Your selected dataframe has " + str(df.shape[1]) + " columns and " + str(df.shape[0]) + " Rows.\n"      
            "There are " + str(mz_table.shape[0]) +
              " columns that have missing values.")
#         mz_table.to_excel('D:/sampledata/missing_and_zero_values.xlsx', freeze_panes=(1,0), index = False)
        return mz_table

missing_zero_values_table(df_train)

df_train.corr()

df_train['region'].value_counts()

df_train

X = df_train.iloc[:, :-1].values #selecting from 4th to before last column of the dataframe
y = df_train.iloc[:, -1].values #selecting last column

X

y

"""Perform label encoding to convert sex column

**Limitation of label Encoding**

Label encoding convert the data in machine readable form, but it assigns a unique number(starting from 0) to each class of data. This may lead to the generation of priority issue in training of data sets. A label with high value may be considered to have high priority than a label having lower value.
"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
X[:, 1] = le.fit_transform(X[:, 1])

X

"""perform label encoder for smoker column"""

X[:, 4] = le.fit_transform(X[:, 4])

X

df_train

df_train['region'].unique()

"""Performing one hot encoding"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [-1])], remainder='passthrough')
X = np.array(ct.fit_transform(X))

X

X[0] # southwest

X[1] #southeast

X[3] #northwest

X[1334] #northeast

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler() #standardizing data of all columns so that all the columns have same scale
X_train = sc.fit_transform(X_train) 
X_test = sc.transform(X_test)

X_train

X_test

"""Linear Regression model"""

from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn import ensemble
from sklearn.linear_model import Lasso,Ridge

linear_model = LinearRegression()
linear_model.fit(X_train,y_train)

#predictions on train data
x_pred = linear_model.predict(X_train)
x_pred = x_pred.reshape(-1,1)

x_pred

#Prediction of validation data
y_predictions = linear_model.predict(X_test)
y_predictions= y_predictions.reshape(-1,1)
y_predictions

def scores_(y,x):
    print('MAE:', metrics.mean_absolute_error(y, x))
    print('MSE:', metrics.mean_squared_error(y, x))
    print('RMSE:', np.sqrt(metrics.mean_squared_error(y, x)))
    print('R2 Score:' ,metrics.r2_score(y,x))

print('InSample_accuracy')
scores_(y_train, x_pred)
print('---------------------------')
print('OutSample_accuracy')
scores_(y_test,y_predictions)

from sklearn.externals import joblib
joblib.dump(linear_model, "/content/drive/MyDrive/Colab Notebooks/Projects/Health Insurance Charges Prediction/HealthInsurancePrediction.pkl")

df_train

from sklearn.externals import joblib
age = 28
sex = 'male' #male=1, female=0
bmi = 33.200
children = 2
smoker = 'no' #yes=1, no=0
region = 'northwest'

"""converting the input record into model accepted format"""

pred_args=[0,1,0,0,28,1,33,3,0]

"""Convert into numpy array format"""

pred_args_arr=np.array(pred_args)
pred_args_arr = pred_args_arr.reshape(1, -1)

"""We need to use transform() method not the fit_transform() method to test for new data"""

pred_args_arr=sc.transform(pred_args_arr)

pred_args_arr

mul_reg = open("/content/drive/MyDrive/Colab Notebooks/Projects/Health Insurance Charges Prediction/HealthInsurancePrediction.pkl","rb")
ml_model = joblib.load(mul_reg)
model_prediction = ml_model.predict(pred_args_arr)

round(float(model_prediction), 2)

"""Putting multiple objects into the pickle file such as linear_model and sc (standardscaler)"""

joblib.dump((linear_model,sc), "/content/drive/MyDrive/Colab Notebooks/Projects/Health Insurance Charges Prediction/HealthInsurancePrediction.pkl")

mul_reg = open("/content/drive/MyDrive/Colab Notebooks/Projects/Health Insurance Charges Prediction/HealthInsurancePrediction.pkl","rb")
lin_model,std_scalar = joblib.load(mul_reg)
model_prediction = lin_model.predict(pred_args_arr)

round(float(model_prediction), 2)